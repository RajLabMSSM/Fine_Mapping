scale_x_continuous(breaks = roundBreaks)
p
cp
effectSNPs <- cojo_DT %>% arrange(desc(COJO.Conditioned_Effect))
cojo_DT
cojo_DT %>% arrange(desc(COJO.Conditioned_Effect))
effectSNPs <- cojo_DT %>% arrange(desc(abs(COJO.Conditioned_Effect)))
effectSNPs
effect_SNPs <- cojo_DT %>% arrange(desc(abs(COJO.Conditioned_Effect)))
effect_SNPs <- cojo_DT %>% arrange(desc(abs(COJO.Conditioned_Effect)))
effect_SNPs$type="effect_SNPs"
effect_SNPs$color "turquoise3"
effect_SNPs <- cojo_DT %>% arrange(desc(abs(COJO.Conditioned_Effect)))
effect_SNPs$type <- "effect_SNPs"
effect_SNPs$color <- "turquoise3"
labelSNPs <- rbind(labelSNPs, effect_SNPs)
labelSNPs
roundBreaks <- seq(plyr::round_any(min(dt$bp),10000), max(dt$bp),250000)
cp <- ggplot(cojo_DT, aes(x=POS, y = COJO.Conditioned_Effect, label=SNP, color= -log10(P))) +
# ylim(yLimits1) +
geom_hline(yintercept=0, alpha=.5, linetype=1, size=.5) +
geom_point(alpha=.5) +
geom_segment(aes(xend=POS, yend=0, color= -log10(P) ), alpha=.5) +
geom_point(data=labelSNPs, pch=21, size=4, colour=labelSNPs$color, stroke=1) +
geom_label_repel(data=labelSNPs, aes(label=SNP), color=labelSNPs$color,
segment.alpha = .5, nudge_x = .5, box.padding = 1, alpha=.8) +
labs(title=paste("Conditional and Stepwise Results: COJO"),
subtitle = paste("Conditioned on:",conditioned_snps,"(Independent SNPs Highlighted)"),
y="-log10(p-value)", x="Position", color="-log10(p-value)") +
theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5) ) +
scale_x_continuous(breaks = roundBreaks)
cp
effect_SNPs <- cojo_DT %>% arrange(desc(abs(COJO.Conditioned_Effect)))
effect_SNPs <- effect_SNPs[1:5,]
effect_SNPs
effect_SNPs$type <- "effect_SNPs"
effect_SNPs$type <- "effect_SNPs"
effect_SNPs$type <- "effect_SNPs"
effect_SNPs$type <- "effect_SNPs"
effect_SNPs$color <- "turquoise3"
labelSNPs <- rbind(labelSNPs, effect_SNPs)
roundBreaks <- seq(plyr::round_any(min(dt$bp),10000), max(dt$bp),250000)
cp <- ggplot(cojo_DT, aes(x=POS, y = COJO.Conditioned_Effect, label=SNP, color= -log10(P))) +
# ylim(yLimits1) +
geom_hline(yintercept=0, alpha=.5, linetype=1, size=.5) +
geom_point(alpha=.5) +
geom_segment(aes(xend=POS, yend=0, color= -log10(P) ), alpha=.5) +
geom_point(data=labelSNPs, pch=21, size=4, colour=labelSNPs$color, stroke=1) +
geom_label_repel(data=labelSNPs, aes(label=SNP), color=labelSNPs$color,
segment.alpha = .5, nudge_x = .5, box.padding = 1, alpha=.8) +
labs(title=paste("Conditional and Stepwise Results: COJO"),
subtitle = paste("Conditioned on:",conditioned_snps,"(Independent SNPs Highlighted)"),
y="-log10(p-value)", x="Position", color="-log10(p-value)") +
theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5) ) +
scale_x_continuous(breaks = roundBreaks)
cp
# Label independent SNPs
ind_SNPs <- subset(cojo_DT, COJO.Independent==T)
ind_SNPs <- cbind(ind_SNPs, type="Independent",color="purple")
labelSNPs <- ind_SNPs#rbind(labelSNPs, ind_SNPs)
effect_SNPs <- cojo_DT %>% arrange(desc(abs(COJO.Conditioned_Effect)))
effect_SNPs <- effect_SNPs[1:5,]
effect_SNPs$type <- "effect_SNPs"
effect_SNPs$color <- "turquoise3"
labelSNPs <- rbind(labelSNPs, effect_SNPs)
roundBreaks <- seq(plyr::round_any(min(dt$bp),10000), max(dt$bp),250000)
cp <- ggplot(cojo_DT, aes(x=POS, y = COJO.Conditioned_Effect, label=SNP, color= -log10(P))) +
# ylim(yLimits1) +
geom_hline(yintercept=0, alpha=.5, linetype=1, size=.5) +
geom_point(alpha=.5) +
geom_segment(aes(xend=POS, yend=0, color= -log10(P) ), alpha=.5) +
geom_point(data=labelSNPs, pch=21, size=4, colour=labelSNPs$color, stroke=1) +
geom_label_repel(data=labelSNPs, aes(label=SNP), color=labelSNPs$color,
segment.alpha = .5, nudge_x = .5, box.padding = 1, alpha=.8) +
labs(title=paste("Conditional and Stepwise Results: COJO"),
subtitle = paste("Conditioned on:",conditioned_snps,"(Independent SNPs Highlighted)"),
y="-log10(p-value)", x="Position", color="-log10(p-value)") +
theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5) ) +
scale_x_continuous(breaks = roundBreaks)
cp
cp <- ggplot(cojo_DT, aes(x=POS, y = -log10(P), label=SNP, color= -log10(P))) +
# ylim(yLimits1) +
geom_hline(yintercept=0, alpha=.5, linetype=1, size=.5) +
geom_point(alpha=.5) +
geom_segment(aes(xend=POS, yend=0, color= -log10(P) ), alpha=.5) +
geom_point(data=labelSNPs, pch=21, size=4, colour=labelSNPs$color, stroke=1) +
geom_label_repel(data=labelSNPs, aes(label=SNP), color=labelSNPs$color,
segment.alpha = .5, nudge_x = .5, box.padding = 1, alpha=.8) +
labs(title=paste("Conditional and Stepwise Results: COJO"),
subtitle = paste("Conditioned on:",conditioned_snps,"(Independent SNPs Highlighted)"),
y="-log10(p-value)", x="Position", color="-log10(p-value)") +
theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5) ) +
scale_x_continuous(breaks = roundBreaks)
cp
LD_link <- function(rs_list, token="df4298d58dc4", population_list=c("CEU"), R2_or_D="r2"){
populations <- ifelse(length(population_list)==1, population_list,
paste(population_list, collapse="%2B"))
rs_IDs <- paste(rs_list, collapse="%0A")
con <-curl(paste("https://ldlink.nci.nih.gov/LDlinkRest/ldmatrix?snps=", rs_IDs,
"&pop=",populations,
"&r2_d=",R2_or_D,
"&token=",token,
sep=""))
open(con)
LD_matrix <- read.delim(con, header = T, row.names = "RS_number" )
LD_matrix <- LD_matrix %>% data.matrix(rownames.force = T)
LD_matrix[is.na(LD_matrix)] <- 0 # | LD_matrix<0
close(con)
return(LD_matrix)
}
ensembl_LD <- function(gene, top_SNPs, flankingSNPs, population="CEU", bp_flank=50000){ #50000
geneSub <- subset(top_SNPs, `Nearest Gene`==gene)
## Specify span by min-max flanking SNPs
# span <- max(flankingSNPs$POS) - min(flankingSNPs$POS)
#  if(span>1000000){print("Over bp span limit")}
#  if(span>100000){print("Over bp span limit (in practice)")}
query_coordinates <- paste(geneSub$CHR,":", min(flankingSNPs$POS) ,"..", max(flankingSNPs$POS) , sep="")
# query_coordinates <- paste(geneSub$CHR,":",geneSub$BP-bp_flank,"..", geneSub$BP+bp_flank, sep="")
genome_build <- "grch37"
server <-  ifelse(genome_build=="grch37",
"https://grch37.rest.ensembl.org", "https://rest.ensembl.org" )
ext <- paste("/ld/human/region/", query_coordinates,
"/1000GENOMES:phase_3:",population,"?",
# "?window_size=", window, # MAX window size is 500kb (either side)
# "?d_prime=0",
sep="")
r <- GET(paste(server, ext, sep = ""), content_type("application/json"))
stop_for_status(r)
LD_df <- fromJSON(toJSON(content(r)))
# Fix column types
LD_df <- lapply(LD_df, unlist) %>% data.frame(stringsAsFactors = F)
LD_df$r2 <- as.numeric(LD_df$r2)
LD_df$d_prime <- as.numeric(LD_df$d_prime)
# Remove accidental self-correlations that don't equal 1
LD_df <- LD_df[LD_df$variation1 != LD_df$variation2,]
# Filter to only positions in flankingSNPs
## Get positions of SNPs in LD df (bc LD API doesn't return position information...)
# LD_df_SNPs <- unique(LD_df$variation1, LD_df$variation2)
# SNP_df_all <- ensembl_variantInfo_chunked(LD_df_SNPs)
# ## Filter by position
# LD_df <- base::merge(LD_df, SNP_df_all[,c("id","start")], by.x="variation1", by.y="id") %>%
#   rename(var1_pos=start)
# LD_df <- base::merge(LD_df, SNP_df_all[,c("id","start")], by.x="variation2", by.y="id") %>%
#   rename(var2_pos=start)
# LD_df <- subset(LD_df, var1_pos %in% flankingSNPs$POS & var2_pos %in% flankingSNPs$POS)
#
# Add self-correlations for all SNPs (=1)
uniqueSNPs <- unique(LD_df$variation1, LD_df$variation2)
sameSNPs <- data.frame(variation1=uniqueSNPs, variation2=uniqueSNPs, r2=1)
LD_df <- rbind(LD_df[c("variation1", "variation2", "r2")], sameSNPs)
LD_df <- LD_df %>% group_by(variation1, variation2) %>% summarise(r2=mean(r2))
#**** Reshape into matrix ****#
LD_matrix <- reshape2::acast(LD_df, variation1 ~ variation2, value.var="r2",
drop=F, fill=0, fun.aggregate=mean)
# Make sure matrix has symmetric dimensions and ordering
commonSNPs <- intersect(row.names(LD_matrix), colnames(LD_matrix))
LD_matrix <- LD_matrix[row.names(LD_matrix) %in% commonSNPs, colnames(LD_matrix) %in% commonSNPs]
LD_matrix <- LD_matrix[ order(row.names(LD_matrix)), order(colnames(LD_matrix))]
dim(LD_matrix)
# View(head(LD_matrix))
return(LD_matrix)
}
top_SNPs
subset_DT
## Specify span by min-max flanking SNPs
# span <- max(flankingSNPs$POS) - min(flankingSNPs$POS)
#  if(span>1000000){print("Over bp span limit")}
#  if(span>100000){print("Over bp span limit (in practice)")}
query_coordinates <- paste(max(subset_DT$CHR),":", min(subset_DT$POS) ,"..", max(subset_DT$POS) , sep="")
query_coordinates
# query_coordinates <- paste(geneSub$CHR,":",geneSub$BP-bp_flank,"..", geneSub$BP+bp_flank, sep="")
genome_build <- "grch37"
server <-  ifelse(genome_build=="grch37",
"https://grch37.rest.ensembl.org", "https://rest.ensembl.org" )
population="CEU"
bp_flank=50000
server <-  ifelse(genome_build=="grch37",
"https://grch37.rest.ensembl.org", "https://rest.ensembl.org" )
ext <- paste("/ld/human/region/", query_coordinates,
"/1000GENOMES:phase_3:",population,"?",
# "?window_size=", window, # MAX window size is 500kb (either side)
# "?d_prime=0",
sep="")
r <- GET(paste(server, ext, sep = ""), content_type("application/json"))
?
GET
r <- httr::GET(paste(server, ext, sep = ""), content_type("application/json"))
r <- httr::GET(paste(server, ext, sep = ""), httr:content_type("application/json"))
r <- httr::GET(paste(server, ext, sep = ""), httr::content_type("application/json"))
stop_for_status(r)
httr::stop_for_status(r)
r <- httr::GET(paste(server, ext, sep = ""), httr::content_type("application/json"))
httr::stop_for_status(r)
?stop_for_status
?fromJSON
LD_df <- jsonlite::fromJSON(jsonlite::toJSON(content(r)))
>content
?
content
LD_df <- jsonlite::fromJSON(jsonlite::toJSON(httr::content(r)))
LD_df
bp_flank=500
r <- httr::GET(paste(server, ext, sep = ""), httr::content_type("application/json"))
## Specify span by min-max flanking SNPs
# span <- max(flankingSNPs$POS) - min(flankingSNPs$POS)
#  if(span>1000000){print("Over bp span limit")}
#  if(span>100000){print("Over bp span limit (in practice)")}
query_coordinates <- paste(max(subset_DT$CHR),":", min(subset_DT$POS) ,"..", max(subset_DT$POS) , sep="")
# query_coordinates <- paste(geneSub$CHR,":",geneSub$BP-bp_flank,"..", geneSub$BP+bp_flank, sep="")
genome_build <- "grch37"
server <-  ifelse(genome_build=="grch37",
"https://grch37.rest.ensembl.org", "https://rest.ensembl.org" )
ext <- paste("/ld/human/region/", query_coordinates,
"/1000GENOMES:phase_3:",population,"?",
# "?window_size=", window, # MAX window size is 500kb (either side)
# "?d_prime=0",
sep="")
r <- httr::GET(paste(server, ext, sep = ""), httr::content_type("application/json"))
httr::stop_for_status(r)
LD_df <- jsonlite::fromJSON(jsonlite::toJSON(httr::content(r)))
LD_df
## Specify span by min-max flanking SNPs
# span <- max(flankingSNPs$POS) - min(flankingSNPs$POS)
#  if(span>1000000){print("Over bp span limit")}
#  if(span>100000){print("Over bp span limit (in practice)")}
# query_coordinates <- paste(max(subset_DT$CHR),":", min(subset_DT$POS) ,"..", max(subset_DT$POS) , sep="")
geneSub <- subset(subset_DT, leadSNP==T)
geneSub
query_coordinates <- paste(geneSub$CHR,":",geneSub$BP-bp_flank,"..", geneSub$BP+bp_flank, sep="")
query_coordinates
query_coordinates <- paste(geneSub$CHR,":",geneSub$POS-bp_flank,"..", geneSub$POS+bp_flank, sep="")
query_coordinates
## Specify span by min-max flanking SNPs
# span <- max(flankingSNPs$POS) - min(flankingSNPs$POS)
#  if(span>1000000){print("Over bp span limit")}
#  if(span>100000){print("Over bp span limit (in practice)")}
# query_coordinates <- paste(max(subset_DT$CHR),":", min(subset_DT$POS) ,"..", max(subset_DT$POS) , sep="")
geneSub <- subset(subset_DT, leadSNP==T)
query_coordinates <- paste(geneSub$CHR,":",geneSub$POS-bp_flank,"..", geneSub$POS+bp_flank, sep="")
genome_build <- "grch37"
server <-  ifelse(genome_build=="grch37",
"https://grch37.rest.ensembl.org", "https://rest.ensembl.org" )
ext <- paste("/ld/human/region/", query_coordinates,
"/1000GENOMES:phase_3:",population,"?",
# "?window_size=", window, # MAX window size is 500kb (either side)
# "?d_prime=0",
sep="")
r <- httr::GET(paste(server, ext, sep = ""), httr::content_type("application/json"))
r <- httr::GET(paste(server, ext, sep = ""), httr::content_type("application/json"))
httr::stop_for_status(r)
LD_df <- jsonlite::fromJSON(jsonlite::toJSON(httr::content(r)))
# Fix column types
LD_df <- lapply(LD_df, unlist) %>% data.frame(stringsAsFactors = F)
LD_df$r2 <- as.numeric(LD_df$r2)
LD_df
LD_df$d_prime <- as.numeric(LD_df$d_prime)
# LD_df_SNPs <- unique(LD_df$variation1, LD_df$variation2)
# SNP_df_all <- ensembl_variantInfo_chunked(LD_df_SNPs)
# ## Filter by position
# LD_df <- base::merge(LD_df, SNP_df_all[,c("id","start")], by.x="variation1", by.y="id") %>%
#   rename(var1_pos=start)
# LD_df <- base::merge(LD_df, SNP_df_all[,c("id","start")], by.x="variation2", by.y="id") %>%
#   rename(var2_pos=start)
# LD_df <- subset(LD_df, var1_pos %in% flankingSNPs$POS & var2_pos %in% flankingSNPs$POS)
#
# Add self-correlations for all SNPs (=1)
uniqueSNPs <- unique(LD_df$variation1, LD_df$variation2)
# LD_df_SNPs <- unique(LD_df$variation1, LD_df$variation2)
# SNP_df_all <- ensembl_variantInfo_chunked(LD_df_SNPs)
# ## Filter by position
# LD_df <- base::merge(LD_df, SNP_df_all[,c("id","start")], by.x="variation1", by.y="id") %>%
#   rename(var1_pos=start)
# LD_df <- base::merge(LD_df, SNP_df_all[,c("id","start")], by.x="variation2", by.y="id") %>%
#   rename(var2_pos=start)
# LD_df <- subset(LD_df, var1_pos %in% flankingSNPs$POS & var2_pos %in% flankingSNPs$POS)
#
# Add self-correlations for all SNPs (=1)
uniqueSNPs <- unique(LD_df$variation1, LD_df$variation2)
sameSNPs <- data.frame(variation1=uniqueSNPs, variation2=uniqueSNPs, r2=1)
LD_df <- rbind(LD_df[c("variation1", "variation2", "r2")], sameSNPs)
LD_df <- LD_df %>% group_by(variation1, variation2) %>% summarise(r2=mean(r2))
#**** Reshape into matrix ****#
LD_matrix <- reshape2::acast(LD_df, variation1 ~ variation2, value.var="r2",
drop=F, fill=0, fun.aggregate=mean)
# Make sure matrix has symmetric dimensions and ordering
commonSNPs <- intersect(row.names(LD_matrix), colnames(LD_matrix))
LD_matrix <- LD_matrix[row.names(LD_matrix) %in% commonSNPs, colnames(LD_matrix) %in% commonSNPs]
LD_matrix <- LD_matrix[ order(row.names(LD_matrix)), order(colnames(LD_matrix))]
dim(LD_matrix)
LD_matrix
r <- httr::GET(paste(server, ext, sep = ""), httr::content_type("application/json"))
httr::stop_for_status(r)
LD_df <- jsonlite::fromJSON(jsonlite::toJSON(httr::content(r)))
LD_df
# Fix column types
LD_df <- lapply(LD_df, unlist) %>% data.frame(stringsAsFactors = F)
LD_df$r2 <- as.numeric(LD_df$r2)
LD_df$d_prime <- as.numeric(LD_df$d_prime)
LD_df
# LD_df_SNPs <- unique(LD_df$variation1, LD_df$variation2)
# SNP_df_all <- ensembl_variantInfo_chunked(LD_df_SNPs)
# ## Filter by position
# LD_df <- base::merge(LD_df, SNP_df_all[,c("id","start")], by.x="variation1", by.y="id") %>%
#   rename(var1_pos=start)
# LD_df <- base::merge(LD_df, SNP_df_all[,c("id","start")], by.x="variation2", by.y="id") %>%
#   rename(var2_pos=start)
# LD_df <- subset(LD_df, var1_pos %in% flankingSNPs$POS & var2_pos %in% flankingSNPs$POS)
#
# Add self-correlations for all SNPs (=1)
uniqueSNPs <- unique(LD_df$variation1, LD_df$variation2)
sameSNPs <- data.frame(variation1=uniqueSNPs, variation2=uniqueSNPs, r2=1)
sameSNPs
LD_df[LD_df$variation2==LD_df$variation1]
LD_df <- rbind(LD_df[c("variation1", "variation2", "r2")], sameSNPs)
LD_df <- LD_df %>% group_by(variation1, variation2) %>% summarise(r2=mean(r2))
LD_df
r <- httr::GET(paste(server, ext, sep = ""), httr::content_type("application/json"))
r <- httr::GET(paste(server, ext, sep = ""), httr::content_type("application/json"))
httr::stop_for_status(r)
LD_df <- jsonlite::fromJSON(jsonlite::toJSON(httr::content(r)))
unique(LD_df$variation2)
# Fix column types
LD_df <- lapply(LD_df, unlist) %>% data.frame(stringsAsFactors = F)
LD_df$r2 <- as.numeric(LD_df$r2)
LD_df$d_prime <- as.numeric(LD_df$d_prime)
LD_df <- jsonlite::fromJSON(jsonlite::toJSON(httr::content(r))) %>% data.table::data.table()
LD_df
# Fix column types
LD_df <- lapply(LD_df, unlist) %>% data.frame(stringsAsFactors = F)
LD_df$r2 <- as.numeric(LD_df$r2)
LD_df$d_prime <- as.numeric(LD_df$d_prime)
LD_df
bp_flank=50000
## Specify span by min-max flanking SNPs
# span <- max(flankingSNPs$POS) - min(flankingSNPs$POS)
#  if(span>1000000){print("Over bp span limit")}
#  if(span>100000){print("Over bp span limit (in practice)")}
# query_coordinates <- paste(max(subset_DT$CHR),":", min(subset_DT$POS) ,"..", max(subset_DT$POS) , sep="")
geneSub <- subset(subset_DT, leadSNP==T)
query_coordinates <- paste(geneSub$CHR,":",geneSub$POS-bp_flank,"..", geneSub$POS+bp_flank, sep="")
genome_build <- "grch37"
server <-  ifelse(genome_build=="grch37",
"https://grch37.rest.ensembl.org", "https://rest.ensembl.org" )
ext <- paste("/ld/human/region/", query_coordinates,
"/1000GENOMES:phase_3:",population,"?",
# "?window_size=", window, # MAX window size is 500kb (either side)
# "?d_prime=0",
sep="")
r <- httr::GET(paste(server, ext, sep = ""), httr::content_type("application/json"))
httr::stop_for_status(r)
LD_df <- jsonlite::fromJSON(jsonlite::toJSON(httr::content(r))) %>% data.table::data.table()
LD_df <- jsonlite::fromJSON(jsonlite::toJSON(httr::content(r))) %>% data.table::data.table()
# Fix column types
LD_df <- lapply(LD_df, unlist) %>% data.frame(stringsAsFactors = F)
LD_df$r2 <- as.numeric(LD_df$r2)
LD_df$d_prime <- as.numeric(LD_df$d_prime)
dim(LD_df)
geneSub <-  subset(subset_DT, leadSNP==T)
server <- "https://grch37.rest.ensembl.org"
ext <- paste("/ld/human/",geneSub$SNP,
"/1000GENOMES:phase_3:CEU?window_size=500;d_prime=0", sep="")
r <- GET(paste(server, ext, sep = ""), content_type("application/json"))
r <- httr::GET(paste(server, ext, sep = ""), httr::content_type("application/json"))
LD_df <- jsonlite::fromJSON(jsonlite::toJSON(httr::content(r)))
LD_df
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
construct_coloc_dataset <- function(subset_path,
sample_size=NA,
proportion_cases=5e-324, # Doesn't allow actual 0, so use smallest number R allows
MAF=NA){
subset_DT <- data.table::fread(subset_path, stringsAsFactors = F) %>% data.frame()
sample_size <- get_sample_size(subset_DT, sample_size)
if("proportion_cases" %in% colnames(subset_DT)){
proportion_cases <- getmode(subset_DT$proportion_cases)
}
if("MAF" %in% colnames(subset_DT)){
MAF <- subset_DT$MAF
}
# List form
dataset <- list(beta = subset_DT$Effect,
varbeta = subset_DT$StdErr^2, # MUST be squared
snp = subset_DT$SNP,
N = sample_size, # [optional]
s = proportion_cases, # use overall proportions
MAF = MAF, # [required]
type="cc")
return(dataset)
}
COLOC <- function(dataset1_path, dataset2_path, MAF,
dataset2_proportion_cases=5e-324){
# https://cran.r-project.org/web/packages/coloc/vignettes/vignette.html
dataset1 <- construct_coloc_dataset("Data/GWAS/Nalls23andMe_2019/LRRK2/LRRK2_Nalls23andMe_2019_subset.txt")
dataset2 <- construct_coloc_dataset("Data/eQTL/MESA_CAU/LRRK2/LRRK2_MESA_CAU_subset.txt",
proportion_cases = dataset2_proportion_cases)
## NOTES: MESA and Fairfax: No sample size (SNP-level), proportion of cases, or freq/MAF info available?
coloc.res <- coloc::coloc.abf(dataset1 = dataset1,
dataset2 = dataset2)
# MAF = dataset1$MAF)
cat("coloc.abf tests the following four hypotheses:",
"     - H0: neither trait has a genetic association in the region",
"     - H1: only trait 1 has a genetic association in the region",
"     - H2: only trait 2 has a genetic association in the region",
"     - H3: both traits are associated, but with different causal variants (one in each dataset)",
"     - H4: both traits are associated and share a single causal variant",sep="\n")
coloc.res$summary>=0.8
return(coloc.res$results)
}
# https://cran.r-project.org/web/packages/coloc/vignettes/vignette.html
dataset1 <- construct_coloc_dataset("Data/GWAS/Nalls23andMe_2019/LRRK2/LRRK2_Nalls23andMe_2019_subset.txt")
# knitr::opts_chunk$set(error = TRUE) # Knit even with errors
# devtools::install_local("echolocatoR/", force = T)
# library("echolocatoR")
source("echolocatoR/R/MAIN.R")
# https://cran.r-project.org/web/packages/coloc/vignettes/vignette.html
dataset1 <- construct_coloc_dataset("Data/GWAS/Nalls23andMe_2019/LRRK2/LRRK2_Nalls23andMe_2019_subset.txt")
dataset2 <- construct_coloc_dataset("Data/eQTL/MESA_CAU/LRRK2/LRRK2_MESA_CAU_subset.txt",
proportion_cases = dataset2_proportion_cases)
dataset2_proportion_cases=5e-324
quickstart()
subset_DT <- data.table::fread(subset_path, stringsAsFactors = F) %>% data.frame()
subset_DT
head(subset_DT)
dim(subset_DT)
subset_DT$Effect
subset_DT$StdErr^2
subset_DT$SNP
sample_size
sample_size <- get_sample_size(subset_DT, sample_size)
sample_size
head(subset_DT)
proportion_cases
proportion_cases <- getmode(subset_DT$proportion_cases)
proportion_cases
55920/1417298
55920 / (55920+1417298)
proportion_cases
MAF
MAF <- subset_DT$MAF
MAF
sample_size
proportion_cases
# https://cran.r-project.org/web/packages/coloc/vignettes/vignette.html
dataset1 <- construct_coloc_dataset("Data/GWAS/Nalls23andMe_2019/LRRK2/LRRK2_Nalls23andMe_2019_subset.txt")
dataset1
dataset2 <- construct_coloc_dataset("Data/eQTL/MESA_CAU/LRRK2/LRRK2_MESA_CAU_subset.txt",
proportion_cases = dataset2_proportion_cases)
dataset2
construct_coloc_dataset <- function(subset_path,
sample_size=NA,
proportion_cases=5e-324, # Doesn't allow actual 0, so use smallest number R allows
MAF=NA,
type="cc"){
subset_DT <- data.table::fread(subset_path, stringsAsFactors = F) %>% data.frame()
sample_size <- get_sample_size(subset_DT, sample_size)
if("proportion_cases" %in% colnames(subset_DT)){
proportion_cases <- getmode(subset_DT$proportion_cases)
}
if("MAF" %in% colnames(subset_DT)){
MAF <- subset_DT$MAF
}
# List form
dataset <- list(beta = subset_DT$Effect,
varbeta = subset_DT$StdErr^2, # MUST be squared
snp = subset_DT$SNP,
N = sample_size, # [optional]
s = proportion_cases, # use overall proportions
MAF = MAF, # [required]
type = type)
return(dataset)
}
# https://cran.r-project.org/web/packages/coloc/vignettes/vignette.html
dataset1 <- construct_coloc_dataset("Data/GWAS/Nalls23andMe_2019/LRRK2/LRRK2_Nalls23andMe_2019_subset.txt")
dataset1
# https://cran.r-project.org/web/packages/coloc/vignettes/vignette.html
dataset1 <- construct_coloc_dataset("Data/GWAS/Nalls23andMe_2019/LRRK2/LRRK2_Nalls23andMe_2019_subset.txt")
dataset1
# https://cran.r-project.org/web/packages/coloc/vignettes/vignette.html
dataset1 <- construct_coloc_dataset("Data/GWAS/Nalls23andMe_2019/LRRK2/LRRK2_Nalls23andMe_2019_subset.txt",
type="cc")
dataset2 <- construct_coloc_dataset("Data/eQTL/MESA_CAU/LRRK2/LRRK2_MESA_CAU_subset.txt",
proportion_cases = dataset2_proportion_cases,
type="quant")
## NOTES: MESA and Fairfax: No sample size (SNP-level), proportion of cases, or freq/MAF info available?
coloc.res <- coloc::coloc.abf(dataset1 = dataset1,
dataset2 = dataset2)
dataset2 <- construct_coloc_dataset("Data/eQTL/MESA_CAU/LRRK2/LRRK2_MESA_CAU_subset.txt",
proportion_cases = dataset2_proportion_cases,
type="cc")
## NOTES: MESA and Fairfax: No sample size (SNP-level), proportion of cases, or freq/MAF info available?
coloc.res <- coloc::coloc.abf(dataset1 = dataset1,
dataset2 = dataset2)
## NOTES: MESA and Fairfax: No sample size (SNP-level), proportion of cases, or freq/MAF info available?
coloc.res <- coloc::coloc.abf(dataset1 = dataset1,
dataset2 = dataset2)
coloc.res$summary>=0.8
str(coloc.res)
head(coloc.res$results)
# awk -F ' ' 'NR==1{print "Coord","CHR","POS",$2,$3,$4,$5,$6 } NR>1{split($1,a,":"); print $1, a[1], a[2], $2, $3, $4, $5, $6}' LRRK2_Fairfax_CD14.txt | tr -s " " "\t" > tmp.txt && mv tmp.txt LRRK2_Fairfax_CD14.txt
awk_cmd <- paste("awk -F '",file_sep,"' 'NR==1{print \"Coord\",\"CHR\",\"POS\",$2,$3,$4,$5,$6 }",
"NR>1{split($",colDict[[chrom_col]],",a,\":\"); print $1, a[1], a[2], $2, $3, $4, $5, $6}' ",
subset_path, " | tr -s ' ' '\t' > tmp.txt && mv tmp.txt ",subset_path, sep="")
file_sep
colDict[[chrom_col]]
# awk -F ' ' 'NR==1{print "Coord","CHR","POS",$2,$3,$4,$5,$6 } NR>1{split($1,a,":"); print $1, a[1], a[2], $2, $3, $4, $5, $6}' LRRK2_Fairfax_CD14.txt | tr -s " " "\t" > tmp.txt && mv tmp.txt LRRK2_Fairfax_CD14.txt
awk_cmd <- paste("awk -F '",file_sep,"' 'NR==1{print \"Coord\",\"CHR\",\"POS\",$2,$3,$4,$5,$6 }",
"NR>1{split($",colDict[[chrom_col]],",a,\":\"); print $1, a[1], a[2], $2, $3, $4, $5, $6}' ",
subset_path, " | tr -s ' ' '\t' > tmp.txt && mv tmp.txt ",subset_path, sep="")
cat("\n",awk_cmd,"\n")
Data_dirs

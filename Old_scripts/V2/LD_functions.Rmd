---
title: "LD_functions"
author: "Brian M. Schilder"
date: "2/5/2019"
output: html_document
---
 
# R Libraries for LD Calculation

```{r example snplist}
snplist <- c("rs614367", "rs11780156","rs4808801","rs12493607","rs204247","rs2943559")
dat <- data.table::fread("Data/GWAS/Nalls23andMe_2019/LRRK2/Multi-finemap/Multi-finemap_results.txt",sep="\t")
snp_df  <- subset(dat, Support >0)
# ## use the Ensembl variation mart
# snp_mart <- useMart(biomart="ENSEMBL_MART_SNP", 
#                     dataset="hsapiens_snp")
# 
# gene="SNCA"
# geneSub <- subset(top_SNPs, `Nearest Gene`==gene) 
# snp_list <- geneSub$SNP
# 
# ## get the synonyms and their source for our SNPs
# results <- getBM(filters = c('snp_filter'), 
#            attributes = c('refsnp_id','synonym_name','synonym_source'), 
#            values = snp_list, 
#            mart = snp_mart) 
```

 
* Other R libraries:
  +[gaston](https://cran.r-project.org/web/packages/gaston/vignettes/gaston.pdf)
  +[ldblock](https://bioconductor.org/packages/devel/bioc/vignettes/ldblock/inst/doc/ldblock.pdf)
  +[MRCIEU/TwoSampleMR]()
  
## snpStats + [LDheatmap](https://cran.r-project.org/web/packages/LDheatmap/LDheatmap.pdf)

```{r snpStats} 
# library(myvariant); #BiocManager::install("myvariant")
library(proxysnps); #devtools::install_github("slowkow/proxysnps")
library(genetics) 
library(snpStats);#devtools::install_github("NikNakk/snpStats")
library(gaston)


proxySNPs_LD <- function(snp_df){    
  vcf <- proxysnps::get_vcf(chrom = unique(snp_df$CHR), 
                            start = min(snp_df$POS), 
                            end = max(snp_df$POS), 
                            pop = "CEU")
  
  
  x <- as.bed.matrix(t(vcf$geno)) 
  ld.x <- gaston::LD(x, c(1,ncol(x)),measure = "r2")

  
  ## snpStats 
  genotypeToSnpMatrix(x =vcf$geno,ref=vcf$meta$REF)  
  snpStats::ld(x = vcf$geno, stats = c("R.squared","D.prime"),depth = 100)
  
  ## Genetics
  LD_matrix <- genetics::LD(g1 = vcf$geno) 
  plot(LD$POS, LD$R.squared, main=geneSub$SNP, xlab="Position", ylab=bquote("R"^2))  
}

library(LDheatmap)
data("CEUData")
LDheatmap(LD_matrix2, LDmeasure="r",
          title=paste("Pairwise LD in R^2"), add.map=TRUE,
          SNP.name=geneSub$SNP, color=grey.colors(20),
          name="myLDgrob", add.key=TRUE)
 
```

## [proxysnps](https://github.com/slowkow/proxysnps)

```{r proxysnps}
# devtools::install_github("https://github.com/slowkow/proxysnps.git")

library(proxysnps)
d <- get_proxies(query = "rs10472076", pop = "EUR")
print(d)
```


## [snpEnrichR](https://academic.oup.com/bioinformatics/article/34/23/4112/5034433)

```{r snpEnrichR}
# devtools::install_github("https://github.com/kartiek/snpEnrichR.git")
library(snpEnrichR) 

qt <- 'psoriasis'
GWAS_SNPS <- getSNPs(qt)
str(GWAS_SNPS,vec.len=1)
```

 
## PAINTOR

[Tutorial](https://github.com/gkichaev/PAINTOR_V3.0/wiki/2a.-Computing-1000-genomes-LD)
```{r}
locus_file <- subset(flankingSNPs, select=c("CHR","POS","SNP","Allele1","Allele2", "P.value")) %>%
  mutate(CHR=paste("chr",CHR,sep=""), Allele1=toupper(Allele1), Allele2=toupper(Allele2), P.value=qnorm(flankingSNPs$P.value)) %>% 
  rename(chr=CHR, pos=POS, rsid=SNP, A0=Allele1, A1=Allele2, Zscore=P.value ) 

write.table(locus_file, "locus_file.hdl", row.names = F, quote = F, col.names = T)


# Download reference panel
system("wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel")
# Download VCF

region <- paste(flankingSNPs$CHR[1],":",min(flankingSNPs$POS),"-",max(flankingSNPs$POS), sep="")
vcf_URL <- "ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz"
system(paste("tabix -fh ",vcf_URL ,region, "> subset.vcf"))
vcf_name <- paste(basename(vcf_URL), ".tbi",sep="")

system(paste("python ../PAINTOR_V3.0/PAINTOR_Utilities/CalcLD_1KG_VCF.py",
" --locus locus_file.hdl",
" --reference ",vcf_name,
" --map integrated_call_samples_v3.20130502.ALL.panel",
" --effect_allele A1",
" --alt_allele A0",
" --population EUR",
" --Zhead Zscore",
" --out_name Data/LD/ld_out",
" --position pos", sep=""))

file.remove(vcf_name)
 

# system("wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz")

"
python ../PAINTOR_V3.0/PAINTOR_Utilities/CalcLD_1KG_VCF.py \
--locus locus_file.hdl \
--reference ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz \
--map integrated_call_samples_v3.20130502.ALL.panel \
--effect_allele A1 \
--alt_allele A0 \
--population CEU \
--Zhead Zscore \
--out_name ld_out \
--position pos
"
 

```

**** http://www.internationalgenome.org/category/variants/ ****\
grep CEU integrated_call_samples.20101123.ALL.panel | cut -f1 > CEU.samples.list

vcf-subset -c CEU.samples.list ALL.chr13.integrated_phase1_v3.20101123.snps_indels_svs.genotypes.vcf.gz | fill-an-ac |

bgzip -c > CEU.chr13.phase1.vcf.gz
    
tabix -h ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20100804/ALL.2of4intersection.20100804.genotypes.vcf.gz 2:39967768-39967768

### VCFtools 

* [Part 1](https://www.biostars.org/p/2909/) 
* [Part 2](https://adairama.wordpress.com/2013/03/26/how-to-calculate-linkage-disequilibrium-using-vcf-of-the-latest-1000-genomes/)

```{r, eval=F}
setwd("Data/LD")

vcfTools_LD <- function(flankingSNPs){
  # write.table(flankingSNPs$SNP, "rsIDs.txt", row.names = F, quote = F, col.names = F)
  # write.table(cbind(flankingSNPs[c("CHR", "POS")],flankingSNPs$POS+1) %>% arrange(POS), "reg.bed", row.names = F, quote = F, col.names = F)
  write.table(data.frame(CHR=flankingSNPs$CHR, POS=flankingSNPs$POS) %>% arrange(POS), "positions.txt", row.names = F, quote = F, col.names = F) ##### * CORRECT!!!! * #####
  
  region <- paste(flankingSNPs$CHR[1],":",min(flankingSNPs$POS),"-",min(flankingSNPs$POS), sep="")
  region2 <- paste(flankingSNPs$CHR[1],":",max(flankingSNPs$POS),"-",max(flankingSNPs$POS), sep="") 
  regions_concat <- paste(paste(flankingSNPs$CHR[1],":",flankingSNPs$POS,"-", flankingSNPs$POS, sep="")[1:10], collapse=" ")  

  
  # system(paste("tabix -fh ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20100804/ALL.2of4intersection.20100804.genotypes.vcf.gz", region, "> subset.vcf"))
  system(paste("tabix -fh ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20100804/ALL.2of4intersection.20100804.genotypes.vcf.gz",regions_concat, "> subset.vcf"))
   # system(paste("tabix -R positions.txt -fh ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20100804/ALL.2of4intersection.20100804.genotypes.vcf.gz  > subset.vcf"))
  # system("vcftools --vcf subset.vcf --positions positions.txt --out new_subset.vcf")
 
   
  # "--hap-r2" (faster?) vs. "--geno-r2" (more accurate?)
  system("vcftools --vcf subset.vcf --hap-r2 --out LDresults") 
  
  LD_df <- read.delim("LDresults.hap.ld", stringsAsFactors = F)
  LD_df <- cbind.data.frame(LD_df, SNP1=base::merge(LD_df, flankingSNPs[c("SNP","POS")], 
                                         by.x="POS1", by.y="POS")$SNP, stringsAsFactors=F)
  LD_df <- cbind.data.frame(LD_df, SNP2=base::merge(LD_df, flankingSNPs[c("SNP","POS")], 
                                       by.x="POS2", by.y="POS")$SNP, stringsAsFactors=F)
   
  # Add back in same-SNP correlations
 
  sameSNPs <-  cbind(LD_df[c("SNP1","SNP2")], R.2=1)
  LD_df <- rbind(LD_df[c("SNP1", "SNP2", "R.2")], sameSNPs) %>% unique()
  LD_df[LD_df$SNP1 == LD_df$SNP2,] 
  str(LD_df)  
  row.names(LD_matrix)==colnames(LD_matrix)
  dim(LD_matrix)
  
  
  LD_matrix <- reshape2::acast(LD_df, SNP1 ~ SNP2, value.var="R.2", fun.aggregate = mean)  
  
  return(LD_matrix)
} 
 
```



### LDlink

* LDlink API
  + To get the LD matrices for each set of variants (without having to download and process an entire VCF file),  use NIH's LDLink API suite (specifically the LDmatrix tool) which uses data from the 1000 Genomes Project. 
  + You first need to register to [get your token here](https://ldlink.nci.nih.gov/?tab=apiaccess) 
  + Then specify which SNPs you want, and from which population(s)
  + A [maximum of 300 SNPs](https://ldlink.nci.nih.gov/?tab=help#LDassoc) are permitted by LDmatrix 
  + All input variants must be on the same chromosome and match a bi-allelic variant
```{r}
LD_link <- function(rs_list,
                    token="df4298d58dc4",
                    population_list=c("CEU"),
                    R2_or_D="r2"){
  print(paste("Querying LDlink:", length(rs_list), "SNPs"))
  populations <- ifelse(length(population_list)==1, population_list, 
                        paste(population_list, collapse="%2B"))
  rs_IDs <- paste(rs_list, collapse="%0A")
  con <- curl::curl(paste("https://ldlink.nci.nih.gov/LDlinkRest/ldmatrix?snps=", rs_IDs, 
                   "&pop=",populations,
                   "&r2_d=",R2_or_D,
                   "&token=",token, 
                   sep=""))
  open(con) 
  LD_matrix <- read.delim(con, header = T, row.names = "RS_number" )  
  LD_matrix <- data.matrix(LD_matrix, rownames.force = T)
  LD_matrix[is.na(LD_matrix)] <- 0 # | LD_matrix<0 
  close(con)
  print(paste("Resulting LD matrix dimensions:", dim(LD_matrix)[1], "x",  dim(LD_matrix)[2]))
  return(LD_matrix)
}
# ld.mat <- LD_link(snp_list)
```

### Ensembl Linkage Disequilibrium Calculator - RestAPI

* Nalls et al. 2019 uses the GRCh37 genome build
* 1 Mb = 1000 kb = 1000000 bp
* 0.5 Mb = 500 kb = 500000 bp

#### VEP Info

[Ensembl Variant Info - API](https://rest.ensembl.org/documentation/info/vep_id_post)
```{r}
# Max number of SNPs/request = 200 
ensembl_variantInfo <- function(rsids){ 
  rsIDs <-paste(paste("\"",rsids,"\"",sep=""), collapse=",")
  body <- paste('{ "ids" : [', rsIDs ,' ] }')
  server <- "http://grch37.rest.ensembl.org"  
  ext <- "/variant_recoder/human/id" 
  
  r <- POST(paste(server, ext, sep = ""), content_type("application/json"), accept("application/json"),
            body = body)
  stop_for_status(r)
   
  SNP_df <- fromJSON(toJSON(content(r)))
  SNP_df$colocated_variants[[3]]$id
  SNP_df <- SNP_df[c("id","start","end","seq_region_name","allele_string",
                  "assembly_name","most_severe_consequence")]
  SNP_df <- lapply( SNP_df, unlist) %>% data.frame(stringsAsFactors = F)
  return(SNP_df)
}

ensembl_variantInfo_chunked <- function(SNP_vector, chunk_size=200){
  SNP_chunks <- split(SNP_vector, ceiling(seq_along(SNP_vector)/chunk_size))
  SNP_df_all <- data.table()
  cat("[ Submitting",length(SNP_vector),"SNPs to Ensembl ]","\n")
  cat("Querying ~ ")
  counter <- 0
  for(chunk in SNP_chunks){
    counter <- counter + length(chunk)
    cat("..",round(counter/length(SNP_vector)*100,digits=1),"%",sep = "")
    results <- ensembl_variantInfo(chunk) 
    SNP_df_all <- rbind(SNP_df_all, results)
  } 
  return(SNP_df_all)
}  
```

#### Window Method

* Cons method
  + Only gives  with a window of 500kb in either direction, not enough
  + Doesn't capture all rsids in flanking SNPs of topSNP

[Ensembl LD Calculator - API for window method](https://rest.ensembl.org/documentation/info/ld_id_get)\
```{r}
  geneSub <-  subset(subset_DT, leadSNP==T)
  server <- "https://grch37.rest.ensembl.org"
  ext <- paste("/ld/human/",geneSub$SNP,
             "/1000GENOMES:phase_3:CEU?window_size=500;d_prime=0", sep="")
 
  r <- httr::GET(paste(server, ext, sep = ""), httr::content_type("application/json"))
  LD_df <- jsonlite::fromJSON(jsonlite::toJSON(httr::content(r))) 
  LD_df
  # Fix column types
  LD_df <- lapply(LD_df, unlist) %>% data.frame(stringsAsFactors = F) 
  LD_df$r2 <- as.numeric(LD_df$r2)
  LD_df$d_prime <- as.numeric(LD_df$d_prime)
  # Remove accidental self-correlations that don't equal 1
  LD_df <- LD_df[LD_df$variation1 != LD_df$variation2,] 
 
stop_for_status(r)
 
# use this if you get a simple nested list back, otherwise inspect its structure
# head(data.frame(t(sapply(content(r),c))))
head(fromJSON(toJSON(content(r))))
```


#### Region Method

* Cons
  + A maximum of 1Mb (1,000,000 bp) queries are allowed (according to documentation).
  + However, in practice only 100,000 bp queries work (a whole order of magnitude less...But still large!)
  + Also only contains 1000 Genomes Data (not HRC)
  
[Ensembl LD Calculator - GUI](http://grch37.ensembl.org/Homo_sapiens/Tools/LD)\
[Ensembl LD Calculator - API Region Method](https://rest.ensembl.org/#Linkage_Disequilibrium)\
```{r Ensembl Linkage Disequilibrium Calculator}   
ensembl_LD <- function(subset_DT, flankingSNPs, population="CEU", bp_flank=50000){ #50000 
  ## Specify span by min-max flanking SNPs
  # span <- max(flankingSNPs$POS) - min(flankingSNPs$POS)
  #  if(span>1000000){print("Over bp span limit")}
  #  if(span>100000){print("Over bp span limit (in practice)")}
  # query_coordinates <- paste(max(subset_DT$CHR),":", min(subset_DT$POS) ,"..", max(subset_DT$POS) , sep="")
  geneSub <- subset(subset_DT, leadSNP==T)
  query_coordinates <- paste(geneSub$CHR,":",geneSub$POS-bp_flank,"..", geneSub$POS+bp_flank, sep="")
  genome_build <- "grch37"
  server <-  ifelse(genome_build=="grch37", 
                    "https://grch37.rest.ensembl.org", "https://rest.ensembl.org" )  
  ext <- paste("/ld/human/region/", query_coordinates,
               "/1000GENOMES:phase_3:",population,"?",
               # "?window_size=", window, # MAX window size is 500kb (either side) 
               # "?d_prime=0",
               sep="")   
  r <- httr::GET(paste(server, ext, sep = ""), httr::content_type("application/json"))  
  httr::stop_for_status(r) 
  LD_df <- jsonlite::fromJSON(jsonlite::toJSON(httr::content(r))) %>% data.table::data.table()
  # Fix column types
  LD_df <- lapply(LD_df, unlist) %>% data.frame(stringsAsFactors = F) 
  LD_df$r2 <- as.numeric(LD_df$r2)
  LD_df$d_prime <- as.numeric(LD_df$d_prime)
  # Remove accidental self-correlations that don't equal 1
  # LD_df <- LD_df[LD_df$variation1 != LD_df$variation2,] 
  
  # Filter to only positions in flankingSNPs
  ## Get positions of SNPs in LD df (bc LD API doesn't return position information...)
  # LD_df_SNPs <- unique(LD_df$variation1, LD_df$variation2)
  # SNP_df_all <- ensembl_variantInfo_chunked(LD_df_SNPs)
  # ## Filter by position
  # LD_df <- base::merge(LD_df, SNP_df_all[,c("id","start")], by.x="variation1", by.y="id") %>%
  #   rename(var1_pos=start)
  # LD_df <- base::merge(LD_df, SNP_df_all[,c("id","start")], by.x="variation2", by.y="id") %>%
  #   rename(var2_pos=start)
  # LD_df <- subset(LD_df, var1_pos %in% flankingSNPs$POS & var2_pos %in% flankingSNPs$POS) 
  # 
  # Add self-correlations for all SNPs (=1)
  uniqueSNPs <- unique(LD_df$variation1, LD_df$variation2)
  sameSNPs <- data.frame(variation1=uniqueSNPs, variation2=uniqueSNPs, r2=1)
  LD_df <- rbind(LD_df[c("variation1", "variation2", "r2")], sameSNPs)
  LD_df <- LD_df %>% group_by(variation1, variation2) %>% summarise(r2=mean(r2))
  
  #**** Reshape into matrix ****#
  LD_matrix <- reshape2::acast(LD_df, variation1 ~ variation2, value.var="r2",  
                               drop=F, fill=0, fun.aggregate=mean) 
  # Make sure matrix has symmetric dimensions and ordering 
  commonSNPs <- intersect(row.names(LD_matrix), colnames(LD_matrix)) 
  LD_matrix <- LD_matrix[row.names(LD_matrix) %in% commonSNPs, colnames(LD_matrix) %in% commonSNPs]
  LD_matrix <- LD_matrix[ order(row.names(LD_matrix)), order(colnames(LD_matrix))] 
  dim(LD_matrix)  
  # View(head(LD_matrix)) 
  return(LD_matrix)
}

# LD <- ensembl_LD(gene = "LRRK2", top_SNPs, )
```
